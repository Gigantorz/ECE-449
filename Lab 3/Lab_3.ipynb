{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ax78GCEPRzB_"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "to3T4ZVKa31V"
      },
      "outputs": [],
      "source": [
        "# !pip install tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import pandas as pd\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.pipeline import Pipeline\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Layer\n",
        "from tensorflow import keras\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "from itertools import permutations, product\n",
        "from statistics import mean\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        },
        "id": "G3FqcG7cgyrZ",
        "outputId": "b324af6a-a76b-4979-88ac-72e3c290ade8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x1000 with 25 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Displaying the MNIST dataset\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Display the first few images from the training set\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5, 5, i + 1)\n",
        "    plt.imshow(x_train[i], cmap='gray')\n",
        "    # plt.title(f\"Label_x: {x_train[i]}\")\n",
        "    plt.title(f\"Label: {y_train[i]}\")\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ye4RIcsszUFH"
      },
      "outputs": [],
      "source": [
        "class Classifier(BaseEstimator, TransformerMixin):\n",
        "  \"\"\"\n",
        "  Creates and trains Convolutional Neural Networks\n",
        "  on the Stratified 5 Fold, and will train and test on the MNIST classification\n",
        "  task using CNN.\n",
        "\n",
        "  ...\n",
        "  Methods\n",
        "  ```````\n",
        "  make_model:\n",
        "    makes desired Convolutional Neural Networks model with the given filter and\n",
        "    learning rate\n",
        "  evaluate:\n",
        "    Evaluates model using stratified 5 fold and will return the mean of the scores\n",
        "  optimal:\n",
        "    Will make a model and will test it by using \"make_model\" and\n",
        "    \"evaluate\" respectively, then will choose the model with the best mean score.\n",
        "  fit:\n",
        "    To fit the dataset with model and to find the optimal model\n",
        "  transform:\n",
        "    returns model\n",
        "  summarize:\n",
        "    To visualy summarize the trained models. Referenced from online tutorial.\n",
        "  test:\n",
        "    To test the model with the test MNIST data.\n",
        "    Testing the performance of the model on the out-of-sample test from MNIST\n",
        "  \"\"\"\n",
        "\n",
        "  def optimal(self, X):\n",
        "    \"\"\" Will call \"make_model\" and \"evaluate\" to make a model with given hyperparameters\n",
        "        and to evaluate the made model. The returned mean accuracy result will be\n",
        "        stored in a dictionary along with its hyperparameter and the hyperparameter\n",
        "        with the highest mean accuracy score will be most optimal model and returned.\n",
        "        Since training takes hours with the MNIST dataset, I will be storing\n",
        "        the model into my drive and will be testing with the MNIST dataset separately.\n",
        "\n",
        "    Parameters\n",
        "    ``````````\n",
        "    X (DataFrame) : Data given but since we are using MNIST dataset, it can just\n",
        "                    be called from Keras. So for this source code we are not going\n",
        "                    to use X.\n",
        "\n",
        "    Returns\n",
        "    ```````\n",
        "    ideal_model (Sequential) : The most optimal CNN model will be returned\n",
        "    \"\"\"\n",
        "    # values = {}\n",
        "    # for (column_name, column_data) in X.iteritems():\n",
        "    #   values[column_name] = column_data\n",
        "    # column_names = values.keys()\n",
        "\n",
        "    num_filters = [16, 32]\n",
        "    learning_rate = [0.001, 0.01]\n",
        "\n",
        "    # The combination with the highest mean scores will be the optimal model\n",
        "    # mean_result (key) : combo list (value)\n",
        "    mean_results_dict = {}\n",
        "\n",
        "    permutation = []\n",
        "\n",
        "    scores, histories = list(), list()\n",
        "    # for filter_combo in product(num_filters, repeat = 3):\n",
        "    for filter in num_filters:\n",
        "      temp_list = list()\n",
        "      temp_list.append(filter)\n",
        "      for rate in learning_rate:\n",
        "        combo = [temp_list, rate]\n",
        "        model = self.make_model(filter = temp_list, lr = rate)\n",
        "        mean_results, model = self.evaluate(model, X)\n",
        "        combo.append(model)\n",
        "        # history = model\n",
        "        scores.append(mean_results)\n",
        "        # histories.append(history)\n",
        "        mean_results_dict[mean_results] = combo\n",
        "      permutation.append(temp_list)\n",
        "\n",
        "    self.summarize(histories)\n",
        "    print(permutation)\n",
        "    optimal = 0\n",
        "    for key in mean_results_dict:\n",
        "      if key > optimal:\n",
        "        optimal = key\n",
        "\n",
        "    print(optimal)\n",
        "    print(\"This is the dictionary\", mean_results_dict)\n",
        "    print(\"This is the optimal combo: \", mean_results_dict[optimal])\n",
        "    arr_optimal = mean_results_dict[optimal]\n",
        "    ideal_model = self.make_model(filter = arr_optimal[0], lr = arr_optimal[1])\n",
        "    ideal_model = mean_results_dict[optimal][2]\n",
        "\n",
        "    # This is the optimal hyper parameter after testing.\n",
        "    # ideal_model = self.make_model(filter = [32], lr = 0.001)\n",
        "    score, ideal_model = self.evaluate(ideal_model, X)\n",
        "    ideal_model.summary()\n",
        "    print(\"The Score is: \", score)\n",
        "    return ideal_model\n",
        "\n",
        "  # from https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-from-scratch-for-mnist-handwritten-digit-classification/\n",
        "  # Deprecated\n",
        "  def summarize(self, histories):\n",
        "    for i in range(len(histories)):\n",
        "      # plot loss\n",
        "      plt.subplot(2, 1, 1)\n",
        "      plt.title('Cross Entropy Loss')\n",
        "      plt.plot(histories[i].history['loss'], color='blue', label='train')\n",
        "      # plt.plot(histories[i].history['val_loss'], color='orange', label='test')\n",
        "      # plot accuracy\n",
        "      plt.subplot(2, 1, 2)\n",
        "      plt.title('Classification Accuracy')\n",
        "      plt.plot(histories[i].history['accuracy'], color='blue', label='train')\n",
        "      # plt.plot(histories[i].history['val_accuracy'], color='orange', label='test')\n",
        "      plt.show()\n",
        "    return\n",
        "\n",
        "  # Will evaluate the model using 5-fold\n",
        "  # --- This will take a while to make ---\n",
        "  def evaluate(self, model, X):\n",
        "    \"\"\" Will evaluate the performance of the CNN model using stratified 5 Fold\n",
        "\n",
        "    Parameters\n",
        "    ``````````\n",
        "    model (Sequential) : CNN model we are evaluating\n",
        "    X (DataFrame) : Not used because we are using mnist data which can be loaded\n",
        "                    from keras.\n",
        "\n",
        "    Returns\n",
        "    ```````\n",
        "    mean_results (float) : returns the mean accuracy score of the stratified 5\n",
        "                          folds scores of the given model.\n",
        "\n",
        "    model (Sequential) : Returns the trained model.... Important\n",
        "    \"\"\"\n",
        "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "    y_train_encoded = to_categorical(y_train)\n",
        "    y_test_encoded = to_categorical(y_test)\n",
        "\n",
        "    # Define EarlyStopping callback to monitor accuracy and stop training when it's no longer improving\n",
        "    early_stopping = EarlyStopping(monitor='accuracy', patience=3, mode = 'max')  # Monitor validation loss and wait for 3 epochs without improvement\n",
        "\n",
        "    list_scores, histories = list(), list()\n",
        "    skf = StratifiedKFold(n_splits = 5)\n",
        "    for train, test in skf.split(X_train, y_train):\n",
        "        model.fit(X_train[train], y_train_encoded[train], epochs = 10, batch_size = 10, callbacks = [early_stopping])\n",
        "        score = model.evaluate(X_train[test], y_train_encoded[test], verbose = 0)\n",
        "        print('Test loss:', score[0])\n",
        "        print('Test accuracy:', score[1]) # we are only going to take into account the accuracy\n",
        "        list_scores.append(score[1] * 100)\n",
        "\n",
        "    print(\"These are the list of scores: \", list_scores)\n",
        "    mean_results = mean(list_scores)\n",
        "    return mean_results, model\n",
        "\n",
        "\n",
        "  def make_model(self, filter = [], lr = 0.001):\n",
        "    \"\"\" Makes the model from the code given on the lab slides, with the given\n",
        "        hyperparameters.\n",
        "        It's good to use ReLU instead of sigmoid because it is more efficient and\n",
        "        mitigates the vanishing gradient problem because ReLU sets negative values\n",
        "        to 0, while leaving positive values unchanged.\n",
        "        But a problem can occur in which a neuron can become inactive and produce\n",
        "        0 for every input, resulting in a loss of learning.\n",
        "        This is called the \"dead neuron\" problem.\n",
        "        We can use variants of ReLU, such as Leaky ReLU and Parametric ReLU to\n",
        "        address this issue.\n",
        "          Those variants are developed to provide a small slope for negative inputs,\n",
        "          preventing neurons from becoming completely inactive.\n",
        "\n",
        "    Parameters\n",
        "    ``````````\n",
        "    filter (int, list) : filter parameter for the CNN model\n",
        "    lr (float) : learning rate value for the Adam optimizer.\n",
        "\n",
        "    Returns\n",
        "    ```````\n",
        "    model (Sequential) : Compiled CNN model with the given hyperparameters.\n",
        "    \"\"\"\n",
        "    # From Code given\n",
        "    model = models.Sequential()\n",
        "\n",
        "    #Define filters and convolutional layers here\n",
        "    model.add(layers.Conv2D(filters=filter[0], kernel_size=(3, 3),\n",
        "    activation='relu', input_shape=(28, 28, 1)))\n",
        "\n",
        "    #Add a maxpooling layer\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    #Flatten the output and give it to a fully connected layer\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    #One hidden layer maps the flattened neurons to output\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "  # DEPRECATED\n",
        "  # Confirmed with TA that we are not using the CNN model of the given diagram,\n",
        "  # but we are using the code that is already provided to make the model.\n",
        "  def make_model2(self, filter = [], lr = 0.001):\n",
        "    # Will make a model of version 2\n",
        "    # From Diagram\n",
        "\n",
        "    model = models.Sequential()\n",
        "    #define filters and convolutional layers here\n",
        "    # we have 16, 3x3 filters.\n",
        "    # Each of the 16 filters produces a 26×26 feature map.\n",
        "    # So the output shape of the Conv2D layer in this case would be 26 x 26 x 16.\n",
        "    model.add(layers.Conv2D(filters=filter[0], kernel_size=(3, 3), activation='relu',\n",
        "          input_shape=(28, 28, 1)))\n",
        "\n",
        "    #  The input_shape parameter is only required for the first layer in the model,\n",
        "    # as subsequent layers can automatically infer\n",
        "    # the input shape from the output shape of the previous layer.\n",
        "    model.add(layers.Conv2D(filters=filter[1], kernel_size=(3, 3), activation='relu'))\n",
        "\n",
        "    #Add a maxpooling layer\n",
        "    # The max pooling layer reduces the dimension by a factor of 2 in this case.\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(filters=filter[2], kernel_size=(3, 3), activation='relu'))\n",
        "\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    #Flatten the output and give it to a fully connected layer\n",
        "    model.add(layers.Flatten())\n",
        "    #one hidden layer maps the flattened neurons to output\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "  def test(self, model):\n",
        "    \"\"\" Will test the model with the MNIST test data and display test loss and\n",
        "        accuracy\n",
        "\n",
        "    Parameter:\n",
        "    model (Sequential) : The most optimal model to be tested.\n",
        "    \"\"\"\n",
        "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "    y_train_encoded = to_categorical(y_train)\n",
        "    y_test_encoded = to_categorical(y_test)\n",
        "\n",
        "    # model.fit(X_train[train], y_train_encoded[train], epochs = 150, batch_size = 10, verbose = 0)\n",
        "    print(\"We are going to test our ideal model on the out-of-sample data\\n\")\n",
        "    score = model.evaluate(X_test, y_test_encoded)\n",
        "    print(\"These are our scores: \")\n",
        "    print('Test loss:', score[0])\n",
        "    print('Test accuracy:', score[1])\n",
        "    return\n",
        "\n",
        "  # This will be executed when fit_transform is called.\n",
        "  def fit(self, X, y=None):\n",
        "    model = Sequential()\n",
        "    model = self.optimal(X)\n",
        "    print(\"This is the most optimal model... Yay!!!\")\n",
        "    model.summary()\n",
        "    model.save(\"CNN_model.keras\") # problem with loading saved models\n",
        "    # Can't load. Costed about a full days worth of training.\n",
        "    self.test(model)\n",
        "    return self\n",
        "\n",
        "  def transform(self, X):\n",
        "    return X\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2XnklwOgHgB",
        "outputId": "be87efb6-8133-4e28-8782-66ad8e708cf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 17s 3ms/step - loss: 0.7406 - accuracy: 0.9284\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.1227 - accuracy: 0.9636\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0993 - accuracy: 0.9711\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0866 - accuracy: 0.9738\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0743 - accuracy: 0.9785\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0718 - accuracy: 0.9803\n",
            "Epoch 7/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0623 - accuracy: 0.9836\n",
            "Epoch 8/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0600 - accuracy: 0.9854\n",
            "Epoch 9/10\n",
            "4800/4800 [==============================] - 16s 3ms/step - loss: 0.0561 - accuracy: 0.9868\n",
            "Epoch 10/10\n",
            "4800/4800 [==============================] - 16s 3ms/step - loss: 0.0532 - accuracy: 0.9877\n",
            "Test loss: 0.29615843296051025\n",
            "Test accuracy: 0.9660833477973938\n",
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 21s 4ms/step - loss: 0.1024 - accuracy: 0.9795\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 18s 4ms/step - loss: 0.0725 - accuracy: 0.9830\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 21s 4ms/step - loss: 0.0707 - accuracy: 0.9842\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 20s 4ms/step - loss: 0.0603 - accuracy: 0.9864\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 16s 3ms/step - loss: 0.0577 - accuracy: 0.9881\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 17s 4ms/step - loss: 0.0566 - accuracy: 0.9890\n",
            "Epoch 7/10\n",
            "4800/4800 [==============================] - 26s 5ms/step - loss: 0.0590 - accuracy: 0.9892\n",
            "Epoch 8/10\n",
            "4800/4800 [==============================] - 19s 4ms/step - loss: 0.0513 - accuracy: 0.9902\n",
            "Epoch 9/10\n",
            "4800/4800 [==============================] - 19s 4ms/step - loss: 0.0503 - accuracy: 0.9908\n",
            "Epoch 10/10\n",
            "4800/4800 [==============================] - 17s 4ms/step - loss: 0.0534 - accuracy: 0.9910\n",
            "Test loss: 0.2635895907878876\n",
            "Test accuracy: 0.9758333563804626\n",
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 18s 4ms/step - loss: 0.0919 - accuracy: 0.9874\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 23s 5ms/step - loss: 0.0651 - accuracy: 0.9889\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 23s 5ms/step - loss: 0.0587 - accuracy: 0.9905\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 20s 4ms/step - loss: 0.0536 - accuracy: 0.9918\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 18s 4ms/step - loss: 0.0567 - accuracy: 0.9921\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 17s 4ms/step - loss: 0.0551 - accuracy: 0.9924\n",
            "Epoch 7/10\n",
            "4800/4800 [==============================] - 18s 4ms/step - loss: 0.0460 - accuracy: 0.9938\n",
            "Epoch 8/10\n",
            "4800/4800 [==============================] - 17s 4ms/step - loss: 0.0496 - accuracy: 0.9938\n",
            "Epoch 9/10\n",
            "4800/4800 [==============================] - 17s 4ms/step - loss: 0.0480 - accuracy: 0.9944\n",
            "Epoch 10/10\n",
            "4800/4800 [==============================] - 18s 4ms/step - loss: 0.0432 - accuracy: 0.9941\n",
            "Test loss: 0.24216321110725403\n",
            "Test accuracy: 0.9859166741371155\n",
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 18s 4ms/step - loss: 0.0971 - accuracy: 0.9906\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 18s 4ms/step - loss: 0.0614 - accuracy: 0.9928\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 16s 3ms/step - loss: 0.0569 - accuracy: 0.9940\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 20s 4ms/step - loss: 0.0544 - accuracy: 0.9940\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 16s 3ms/step - loss: 0.0505 - accuracy: 0.9943\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 17s 4ms/step - loss: 0.0423 - accuracy: 0.9948\n",
            "Epoch 7/10\n",
            "4800/4800 [==============================] - 18s 4ms/step - loss: 0.0464 - accuracy: 0.9950\n",
            "Epoch 8/10\n",
            "4800/4800 [==============================] - 23s 5ms/step - loss: 0.0428 - accuracy: 0.9953\n",
            "Epoch 9/10\n",
            "4800/4800 [==============================] - 20s 4ms/step - loss: 0.0461 - accuracy: 0.9951\n",
            "Epoch 10/10\n",
            "4800/4800 [==============================] - 16s 3ms/step - loss: 0.0444 - accuracy: 0.9959\n",
            "Test loss: 0.18537397682666779\n",
            "Test accuracy: 0.987500011920929\n",
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 18s 4ms/step - loss: 0.0929 - accuracy: 0.9932\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 16s 3ms/step - loss: 0.0568 - accuracy: 0.9947\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 16s 3ms/step - loss: 0.0580 - accuracy: 0.9944\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 16s 3ms/step - loss: 0.0497 - accuracy: 0.9953\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 17s 4ms/step - loss: 0.0440 - accuracy: 0.9960\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0520 - accuracy: 0.9956\n",
            "Epoch 7/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0494 - accuracy: 0.9955\n",
            "Epoch 8/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0464 - accuracy: 0.9959\n",
            "Test loss: 0.1313755363225937\n",
            "Test accuracy: 0.9934166669845581\n",
            "These are the list of scores:  [96.60833477973938, 97.58333563804626, 98.59166741371155, 98.7500011920929, 99.34166669845581]\n",
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.7387 - accuracy: 0.8555\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 14s 3ms/step - loss: 0.5759 - accuracy: 0.8370\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 14s 3ms/step - loss: 0.5978 - accuracy: 0.8218\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.4665 - accuracy: 0.8574\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 14s 3ms/step - loss: 0.4260 - accuracy: 0.8699\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 16s 3ms/step - loss: 0.4126 - accuracy: 0.8730\n",
            "Epoch 7/10\n",
            "4800/4800 [==============================] - 14s 3ms/step - loss: 0.4051 - accuracy: 0.8763\n",
            "Epoch 8/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3999 - accuracy: 0.8788\n",
            "Epoch 9/10\n",
            "4800/4800 [==============================] - 14s 3ms/step - loss: 0.3967 - accuracy: 0.8783\n",
            "Epoch 10/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3936 - accuracy: 0.8794\n",
            "Test loss: 0.4313407838344574\n",
            "Test accuracy: 0.8813333511352539\n",
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3938 - accuracy: 0.8807\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3898 - accuracy: 0.8824\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3881 - accuracy: 0.8821\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3859 - accuracy: 0.8824\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 14s 3ms/step - loss: 0.3853 - accuracy: 0.8819\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3850 - accuracy: 0.8838\n",
            "Epoch 7/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3828 - accuracy: 0.8844\n",
            "Epoch 8/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3828 - accuracy: 0.8838\n",
            "Epoch 9/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3810 - accuracy: 0.8847\n",
            "Epoch 10/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3812 - accuracy: 0.8846\n",
            "Test loss: 0.38671427965164185\n",
            "Test accuracy: 0.8834166526794434\n",
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3825 - accuracy: 0.8833\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 14s 3ms/step - loss: 0.3794 - accuracy: 0.8861\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 14s 3ms/step - loss: 0.3786 - accuracy: 0.8848\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3769 - accuracy: 0.8859\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3783 - accuracy: 0.8854\n",
            "Test loss: 0.40233731269836426\n",
            "Test accuracy: 0.8834166526794434\n",
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3759 - accuracy: 0.8870\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3741 - accuracy: 0.8874\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 14s 3ms/step - loss: 0.3736 - accuracy: 0.8884\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3720 - accuracy: 0.8889\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3709 - accuracy: 0.8891\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 17s 3ms/step - loss: 0.3710 - accuracy: 0.8881\n",
            "Epoch 7/10\n",
            "4800/4800 [==============================] - 20s 4ms/step - loss: 0.3716 - accuracy: 0.8886\n",
            "Epoch 8/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3705 - accuracy: 0.8894\n",
            "Epoch 9/10\n",
            "4800/4800 [==============================] - 16s 3ms/step - loss: 0.3704 - accuracy: 0.8896\n",
            "Epoch 10/10\n",
            "4800/4800 [==============================] - 16s 3ms/step - loss: 0.3685 - accuracy: 0.8895\n",
            "Test loss: 0.4103321433067322\n",
            "Test accuracy: 0.8765000104904175\n",
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3860 - accuracy: 0.8823\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3853 - accuracy: 0.8839\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3819 - accuracy: 0.8859\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 17s 3ms/step - loss: 0.3822 - accuracy: 0.8837\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 16s 3ms/step - loss: 0.3822 - accuracy: 0.8845\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 14s 3ms/step - loss: 0.3810 - accuracy: 0.8854\n",
            "Test loss: 0.36205512285232544\n",
            "Test accuracy: 0.8917499780654907\n",
            "These are the list of scores:  [88.13333511352539, 88.34166526794434, 88.34166526794434, 87.65000104904175, 89.17499780654907]\n",
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 16s 3ms/step - loss: 0.4820 - accuracy: 0.9410\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.1127 - accuracy: 0.9671\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0808 - accuracy: 0.9754\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0729 - accuracy: 0.9790\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0630 - accuracy: 0.9823\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0550 - accuracy: 0.9844\n",
            "Epoch 7/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0539 - accuracy: 0.9857\n",
            "Epoch 8/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0478 - accuracy: 0.9873\n",
            "Epoch 9/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0497 - accuracy: 0.9887\n",
            "Epoch 10/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0457 - accuracy: 0.9902\n",
            "Test loss: 0.28795331716537476\n",
            "Test accuracy: 0.9640833139419556\n",
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.1038 - accuracy: 0.9814\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0696 - accuracy: 0.9847\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 18s 4ms/step - loss: 0.0549 - accuracy: 0.9864\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 19s 4ms/step - loss: 0.0511 - accuracy: 0.9888\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 16s 3ms/step - loss: 0.0495 - accuracy: 0.9895\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 16s 3ms/step - loss: 0.0460 - accuracy: 0.9901\n",
            "Epoch 7/10\n",
            "4800/4800 [==============================] - 17s 3ms/step - loss: 0.0434 - accuracy: 0.9912\n",
            "Epoch 8/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0437 - accuracy: 0.9919\n",
            "Epoch 9/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0460 - accuracy: 0.9920\n",
            "Epoch 10/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0434 - accuracy: 0.9927\n",
            "Test loss: 0.2622692584991455\n",
            "Test accuracy: 0.9771666526794434\n",
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0862 - accuracy: 0.9887\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0599 - accuracy: 0.9902\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0399 - accuracy: 0.9931\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0434 - accuracy: 0.9933\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0428 - accuracy: 0.9935\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0436 - accuracy: 0.9935\n",
            "Epoch 7/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0428 - accuracy: 0.9943\n",
            "Epoch 8/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0390 - accuracy: 0.9949\n",
            "Epoch 9/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0389 - accuracy: 0.9947\n",
            "Epoch 10/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0381 - accuracy: 0.9951\n",
            "Test loss: 0.2389097660779953\n",
            "Test accuracy: 0.984499990940094\n",
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0852 - accuracy: 0.9928\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0518 - accuracy: 0.9940\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0519 - accuracy: 0.9944\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0481 - accuracy: 0.9947\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0389 - accuracy: 0.9955\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0359 - accuracy: 0.9957\n",
            "Epoch 7/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0378 - accuracy: 0.9961\n",
            "Epoch 8/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0402 - accuracy: 0.9960\n",
            "Epoch 9/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0347 - accuracy: 0.9964\n",
            "Epoch 10/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0377 - accuracy: 0.9961\n",
            "Test loss: 0.18387597799301147\n",
            "Test accuracy: 0.9882500171661377\n",
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0765 - accuracy: 0.9939\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0489 - accuracy: 0.9948\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0474 - accuracy: 0.9957\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0365 - accuracy: 0.9964\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0409 - accuracy: 0.9961\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0456 - accuracy: 0.9958\n",
            "Epoch 7/10\n",
            "4800/4800 [==============================] - 16s 3ms/step - loss: 0.0420 - accuracy: 0.9962\n",
            "Test loss: 0.07148751616477966\n",
            "Test accuracy: 0.9950000047683716\n",
            "These are the list of scores:  [96.40833139419556, 97.71666526794434, 98.4499990940094, 98.82500171661377, 99.50000047683716]\n",
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 16s 3ms/step - loss: 0.8642 - accuracy: 0.8418\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.4657 - accuracy: 0.8590\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.4300 - accuracy: 0.8685\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.4159 - accuracy: 0.8729\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.4070 - accuracy: 0.8767\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 18s 4ms/step - loss: 0.4019 - accuracy: 0.8772\n",
            "Epoch 7/10\n",
            "4800/4800 [==============================] - 19s 4ms/step - loss: 0.3983 - accuracy: 0.8792\n",
            "Epoch 8/10\n",
            "4800/4800 [==============================] - 16s 3ms/step - loss: 0.3945 - accuracy: 0.8790\n",
            "Epoch 9/10\n",
            "4800/4800 [==============================] - 17s 4ms/step - loss: 0.3919 - accuracy: 0.8809\n",
            "Epoch 10/10\n",
            "4800/4800 [==============================] - 17s 4ms/step - loss: 0.3925 - accuracy: 0.8813\n",
            "Test loss: 0.3931155204772949\n",
            "Test accuracy: 0.8815833330154419\n",
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3907 - accuracy: 0.8810\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3874 - accuracy: 0.8826\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3867 - accuracy: 0.8821\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3860 - accuracy: 0.8831\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3840 - accuracy: 0.8834\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3833 - accuracy: 0.8843\n",
            "Epoch 7/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3818 - accuracy: 0.8838\n",
            "Epoch 8/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3807 - accuracy: 0.8852\n",
            "Epoch 9/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3798 - accuracy: 0.8852\n",
            "Epoch 10/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3792 - accuracy: 0.8859\n",
            "Test loss: 0.3985559344291687\n",
            "Test accuracy: 0.8792499899864197\n",
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3828 - accuracy: 0.8841\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3790 - accuracy: 0.8851\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3778 - accuracy: 0.8850\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 16s 3ms/step - loss: 0.3771 - accuracy: 0.8860\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3768 - accuracy: 0.8870\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3769 - accuracy: 0.8873\n",
            "Epoch 7/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3760 - accuracy: 0.8869\n",
            "Epoch 8/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3750 - accuracy: 0.8865\n",
            "Epoch 9/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3747 - accuracy: 0.8881\n",
            "Epoch 10/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3738 - accuracy: 0.8871\n",
            "Test loss: 0.3922477662563324\n",
            "Test accuracy: 0.8840833306312561\n",
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3738 - accuracy: 0.8876\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3728 - accuracy: 0.8876\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3706 - accuracy: 0.8890\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3701 - accuracy: 0.8888\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3697 - accuracy: 0.8888\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3686 - accuracy: 0.8890\n",
            "Epoch 7/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3699 - accuracy: 0.8894\n",
            "Epoch 8/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3698 - accuracy: 0.8880\n",
            "Epoch 9/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3687 - accuracy: 0.8894\n",
            "Epoch 10/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3684 - accuracy: 0.8899\n",
            "Test loss: 0.4107430875301361\n",
            "Test accuracy: 0.8789166808128357\n",
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3841 - accuracy: 0.8839\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3825 - accuracy: 0.8851\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3813 - accuracy: 0.8848\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3810 - accuracy: 0.8848\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3801 - accuracy: 0.8851\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3806 - accuracy: 0.8855\n",
            "Epoch 7/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3814 - accuracy: 0.8846\n",
            "Epoch 8/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3796 - accuracy: 0.8847\n",
            "Epoch 9/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.3802 - accuracy: 0.8843\n",
            "Test loss: 0.3629342317581177\n",
            "Test accuracy: 0.8953333497047424\n",
            "These are the list of scores:  [88.15833330154419, 87.92499899864197, 88.40833306312561, 87.89166808128357, 89.53333497047424]\n",
            "[[16], [32]]\n",
            "98.17999958992004\n",
            "This is the dictionary {98.17500114440918: [[16], 0.001, <keras.src.engine.sequential.Sequential object at 0x0000020A80250F70>], 88.32833290100098: [[16], 0.01, <keras.src.engine.sequential.Sequential object at 0x0000020A802164A0>], 98.17999958992004: [[32], 0.001, <keras.src.engine.sequential.Sequential object at 0x0000020A79213E80>], 88.38333368301392: [[32], 0.01, <keras.src.engine.sequential.Sequential object at 0x0000020A7B504B20>]}\n",
            "This is the optimal combo:  [[32], 0.001, <keras.src.engine.sequential.Sequential object at 0x0000020A79213E80>]\n",
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 16s 3ms/step - loss: 0.0488 - accuracy: 0.9961\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 16s 3ms/step - loss: 0.0402 - accuracy: 0.9959\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0422 - accuracy: 0.9966\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0397 - accuracy: 0.9965\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0289 - accuracy: 0.9973\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0342 - accuracy: 0.9972\n",
            "Epoch 7/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0377 - accuracy: 0.9972\n",
            "Epoch 8/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0332 - accuracy: 0.9970\n",
            "Test loss: 0.13163399696350098\n",
            "Test accuracy: 0.9938333630561829\n",
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0657 - accuracy: 0.9956\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0474 - accuracy: 0.9966\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0380 - accuracy: 0.9969\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0373 - accuracy: 0.9972\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0401 - accuracy: 0.9971\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0402 - accuracy: 0.9969\n",
            "Epoch 7/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0341 - accuracy: 0.9975\n",
            "Epoch 8/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0335 - accuracy: 0.9976\n",
            "Epoch 9/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0311 - accuracy: 0.9979\n",
            "Epoch 10/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0472 - accuracy: 0.9969\n",
            "Test loss: 0.18455100059509277\n",
            "Test accuracy: 0.9909166693687439\n",
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0515 - accuracy: 0.9969\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0450 - accuracy: 0.9973\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0291 - accuracy: 0.9977\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0399 - accuracy: 0.9975\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0300 - accuracy: 0.9976\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0452 - accuracy: 0.9974\n",
            "Test loss: 0.0912899598479271\n",
            "Test accuracy: 0.9955000281333923\n",
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0499 - accuracy: 0.9971\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0356 - accuracy: 0.9976\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0364 - accuracy: 0.9978\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0348 - accuracy: 0.9978\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0393 - accuracy: 0.9976\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0362 - accuracy: 0.9979\n",
            "Epoch 7/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0323 - accuracy: 0.9981\n",
            "Epoch 8/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0281 - accuracy: 0.9982\n",
            "Epoch 9/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0297 - accuracy: 0.9981\n",
            "Epoch 10/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0330 - accuracy: 0.9981\n",
            "Test loss: 0.12630905210971832\n",
            "Test accuracy: 0.9946666955947876\n",
            "Epoch 1/10\n",
            "4800/4800 [==============================] - 16s 3ms/step - loss: 0.0519 - accuracy: 0.9974\n",
            "Epoch 2/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0496 - accuracy: 0.9971\n",
            "Epoch 3/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0369 - accuracy: 0.9978\n",
            "Epoch 4/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0262 - accuracy: 0.9983\n",
            "Epoch 5/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0410 - accuracy: 0.9979\n",
            "Epoch 6/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0343 - accuracy: 0.9980\n",
            "Epoch 7/10\n",
            "4800/4800 [==============================] - 15s 3ms/step - loss: 0.0378 - accuracy: 0.9982\n",
            "Test loss: 0.07327204942703247\n",
            "Test accuracy: 0.9972500205039978\n",
            "These are the list of scores:  [99.38333630561829, 99.09166693687439, 99.55000281333923, 99.46666955947876, 99.72500205039978]\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_7 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 13, 13, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 5408)              0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                54090     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 54410 (212.54 KB)\n",
            "Trainable params: 54410 (212.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "The Score is:  99.44333553314209\n",
            "This is the most optimal model... Yay!!!\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_7 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 13, 13, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 5408)              0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                54090     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 54410 (212.54 KB)\n",
            "Trainable params: 54410 (212.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "We are going to test our ideal model on the out-of-sample data\n",
            "\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 2.1903 - accuracy: 0.9750\n",
            "These are our scores: \n",
            "Test loss: 2.1902506351470947\n",
            "Test accuracy: 0.9750000238418579\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Not necessary\n",
        "data = pd.DataFrame()\n",
        "cnn = Classifier()\n",
        "data = cnn.fit_transform(data) # doesn't return anyting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJPj50nsRQx8"
      },
      "source": [
        "# Final Conclusion\n",
        "After doing hyperparameter exploration. I have found that the most optimal hyperparameters are 32 filters, and a 0.001 learning rate. With using the most optimal hyperparameter, I get an accuracy score of 96% when being tested with the out-of-sample data. This showcases why Convolutional Neural Networks is the most effective algorithm for image classification / computer vision.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
